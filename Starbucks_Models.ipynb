{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "Starbucks_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GniwT/Udacity_Starbucks_Capstone_Project/blob/master/Starbucks_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka-1dwHTRCTr",
        "colab_type": "text"
      },
      "source": [
        "### **Predictive Modeling**\n",
        "I am building three models to predict the effectiveness of each offer, depending on the offer attributes and the demographics of the customers.\n",
        "\n",
        "Models -\n",
        "\n",
        "\n",
        "*   Logistic Regression\n",
        "*   Random Forest Classifier\n",
        "\n",
        "*   XGBoost\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh35K9rnRAOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bd6bd764-5efd-4a07-ff5e-7a4c38936db5"
      },
      "source": [
        "# import Google Colab\n",
        "# this steps is unnecessary if running on local Jupyter Notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VowBkSBPaF8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "56402f1b-5164-4fd2-a907-89c55c84f585"
      },
      "source": [
        "!pip install --upgrade scikit-learn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.15.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-0.23.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvl_e1RHU_Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn \n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from xgboost.sklearn import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQymHUyaVbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5fc3010e-8de4-460a-86f8-b921e6a7f434"
      },
      "source": [
        "# import the dataframe built in ETL .ipynb\n",
        "main_df = pd.read_csv('/content/drive/My Drive/starbucks_model_df.csv')\n",
        "\n",
        "# drop the unnecessary columns\n",
        "main_df = main_df.drop(['customer_id', 'time', 'email', 'offer_type'], axis = 1)\n",
        "main_df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['offer_id', 'difficulty', 'duration', 'reward', 'web', 'mobile',\n",
              "       'social', 'bogo', 'informational', 'discount', 'gender', 'age_bin',\n",
              "       'income_bin', 'membership_since', 'total_amount', 'cust_action'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOHV_eSaVfbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the columns should be encoded vs scaled\n",
        "cate_col = ['offer_id', 'gender', 'age_bin', 'income_bin', 'membership_since']\n",
        "num_col  = ['difficulty', 'duration', 'reward', 'total_amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq8pS7r3Vyv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define X and y\n",
        "X = main_df.drop('cust_action', axis = 1)\n",
        "y = main_df.cust_action\n",
        "\n",
        "# split the data into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3POPgI7gRjQo",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluate naive predictor performance**\n",
        "\n",
        "\n",
        "*   A naive predictor assumes that all customer offers were successful"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XPIF_6bRiBV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fb7964d-ffdb-46a9-9252-c7505ea7e112"
      },
      "source": [
        "naive_pred_accuracy = accuracy_score(y_train, np.ones(len(y_train)))\n",
        "naive_pred_f1= f1_score(y_train, np.ones(len(y_train)))\n",
        "\n",
        "print(\"Naive predictor accuracy: %.3f\" % (naive_pred_accuracy))\n",
        "print(\"Naive predictor f1-score: %.3f\" % (naive_pred_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive predictor accuracy: 0.301\n",
            "Naive predictor f1-score: 0.463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJh-3sSPWlOA",
        "colab_type": "text"
      },
      "source": [
        "Feature Engineering\n",
        "\n",
        "\n",
        "*   Perform OneHotEncoder on categorical columns\n",
        "*   Perform standard scaling on numerical columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzQVKukaUJQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instantiate OneHotEncoder and StandardScaler\n",
        "ohe = OneHotEncoder()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "ct = make_column_transformer(\n",
        "    (ohe, cate_col),\n",
        "    (scaler, num_col),\n",
        "    remainder = 'passthrough')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2S0aLKzXSy4",
        "colab_type": "text"
      },
      "source": [
        "### **Construct Logistic Regression model**\n",
        "\n",
        "\n",
        "*   Perform random search of hyperparameter tuning \n",
        "\n",
        "*   The results suggest that a logistic regression model could give the better accuracy and f1-score than the naive predictor.\n",
        "\n",
        "    *   Accuracy\n",
        "\n",
        "      *   Naive predictor: 0.301\n",
        "      *   Logistic regression:  0.792\n",
        "    *   F1-score\n",
        "      *   Naive predictor: 0.463\n",
        "      *   Logistic regression: 0.573"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHJ7DmKpHzrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d5781150-d752-42dc-c55e-9c53732d4e1b"
      },
      "source": [
        "# hyperparameters ranges\n",
        "\n",
        "params_lr = {}\n",
        "params_lr['logisticregression__penalty'] = ['l1','l2']\n",
        "params_lr['logisticregression__C'] = [0.1, 1, 10]\n",
        "params_lr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'logisticregression__C': [0.1, 1, 10],\n",
              " 'logisticregression__penalty': ['l1', 'l2']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mEnvpBKHzhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "888daa6e-5dc9-4e3f-a2d7-ba0fecb33204"
      },
      "source": [
        "# build a pipeline \n",
        "# set up randomized search cross validation\n",
        "\n",
        "lr = LogisticRegression(solver = 'liblinear', random_state = 1)\n",
        "pipe_lr = make_pipeline(ct, lr)\n",
        "rand_lr = RandomizedSearchCV(pipe_lr, params_lr, cv = 5, scoring = 'accuracy')\n",
        "%time rand_lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:282: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 38.5 s, sys: 2.96 s, total: 41.5 s\n",
            "Wall time: 38.2 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('columntransformer',\n",
              "                                              ColumnTransformer(remainder='passthrough',\n",
              "                                                                transformers=[('onehotencoder',\n",
              "                                                                               OneHotEncoder(),\n",
              "                                                                               ['offer_id',\n",
              "                                                                                'gender',\n",
              "                                                                                'age_bin',\n",
              "                                                                                'income_bin',\n",
              "                                                                                'membership_since']),\n",
              "                                                                              ('standardscaler',\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               ['difficulty',\n",
              "                                                                                'duration',\n",
              "                                                                                'reward',\n",
              "                                                                                'total_amount'])])),\n",
              "                                             ('logisticregression',\n",
              "                                              LogisticRegression(random_state=1,\n",
              "                                                                 solver='liblinear'))]),\n",
              "                   param_distributions={'logisticregression__C': [0.1, 1, 10],\n",
              "                                        'logisticregression__penalty': ['l1',\n",
              "                                                                        'l2']},\n",
              "                   scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVSNgfkIHzaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "747a6841-4d55-4cb5-c203-b6aac77940e1"
      },
      "source": [
        "# print the results of the top estimators\n",
        "results = pd.DataFrame(rand_lr.cv_results_)\n",
        "results.sort_values('rank_test_score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_logisticregression__penalty</th>\n",
              "      <th>param_logisticregression__C</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.414199</td>\n",
              "      <td>0.518633</td>\n",
              "      <td>0.022761</td>\n",
              "      <td>0.000505</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'logisticregression__penalty': 'l1', 'logisti...</td>\n",
              "      <td>0.788722</td>\n",
              "      <td>0.795771</td>\n",
              "      <td>0.790132</td>\n",
              "      <td>0.796053</td>\n",
              "      <td>0.794549</td>\n",
              "      <td>0.793045</td>\n",
              "      <td>0.003030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.412165</td>\n",
              "      <td>0.503704</td>\n",
              "      <td>0.022941</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>l1</td>\n",
              "      <td>1</td>\n",
              "      <td>{'logisticregression__penalty': 'l1', 'logisti...</td>\n",
              "      <td>0.787688</td>\n",
              "      <td>0.796335</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.795771</td>\n",
              "      <td>0.795019</td>\n",
              "      <td>0.792857</td>\n",
              "      <td>0.003562</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.346516</td>\n",
              "      <td>0.019615</td>\n",
              "      <td>0.022810</td>\n",
              "      <td>0.000447</td>\n",
              "      <td>l2</td>\n",
              "      <td>1</td>\n",
              "      <td>{'logisticregression__penalty': 'l2', 'logisti...</td>\n",
              "      <td>0.787406</td>\n",
              "      <td>0.796429</td>\n",
              "      <td>0.789286</td>\n",
              "      <td>0.795865</td>\n",
              "      <td>0.795113</td>\n",
              "      <td>0.792820</td>\n",
              "      <td>0.003724</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.206354</td>\n",
              "      <td>0.002219</td>\n",
              "      <td>0.022689</td>\n",
              "      <td>0.000490</td>\n",
              "      <td>l1</td>\n",
              "      <td>10</td>\n",
              "      <td>{'logisticregression__penalty': 'l1', 'logisti...</td>\n",
              "      <td>0.787312</td>\n",
              "      <td>0.796335</td>\n",
              "      <td>0.789286</td>\n",
              "      <td>0.795771</td>\n",
              "      <td>0.795113</td>\n",
              "      <td>0.792763</td>\n",
              "      <td>0.003718</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.347444</td>\n",
              "      <td>0.039625</td>\n",
              "      <td>0.022748</td>\n",
              "      <td>0.000705</td>\n",
              "      <td>l2</td>\n",
              "      <td>10</td>\n",
              "      <td>{'logisticregression__penalty': 'l2', 'logisti...</td>\n",
              "      <td>0.787312</td>\n",
              "      <td>0.796335</td>\n",
              "      <td>0.789286</td>\n",
              "      <td>0.795771</td>\n",
              "      <td>0.795113</td>\n",
              "      <td>0.792763</td>\n",
              "      <td>0.003718</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.304824</td>\n",
              "      <td>0.018882</td>\n",
              "      <td>0.022592</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'logisticregression__penalty': 'l2', 'logisti...</td>\n",
              "      <td>0.787594</td>\n",
              "      <td>0.796053</td>\n",
              "      <td>0.789286</td>\n",
              "      <td>0.795865</td>\n",
              "      <td>0.794361</td>\n",
              "      <td>0.792632</td>\n",
              "      <td>0.003513</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0       1.414199      0.518633  ...        0.003030                1\n",
              "2       4.412165      0.503704  ...        0.003562                2\n",
              "3       0.346516      0.019615  ...        0.003724                3\n",
              "4       0.206354      0.002219  ...        0.003718                4\n",
              "5       0.347444      0.039625  ...        0.003718                4\n",
              "1       0.304824      0.018882  ...        0.003513                6\n",
              "\n",
              "[6 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLKSifr3U_KY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43d21462-5487-435d-c718-e56509b2a85c"
      },
      "source": [
        "# make the prediction from the test set with the best estimators\n",
        "y_pred_lr = rand_lr.predict(X_test)\n",
        "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
        "lr_f1 = f1_score(y_test, y_pred_lr, average='binary')\n",
        "\n",
        "print('accuracy score of logistic regression: ', lr_accuracy )\n",
        "print('F1 score of logistic regression: ', lr_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score of logistic regression:  0.7915194346289752\n",
            "F1 score of logistic regression:  0.5727930981358804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnVTs7zhdVMn",
        "colab_type": "text"
      },
      "source": [
        "### **Construct Random Forest Classifier**\n",
        "\n",
        "*   Perform randomized search of hyperparameter tuning\n",
        "*   The results suggest that random forest classifier could give the better accuracy and f1-score than the naive predictor.\n",
        "    * Accuracy\n",
        "      * Naive predictor: 0.301\n",
        "      * Random Forest Classifier: 0.875\n",
        "    * F1-score\n",
        "      * Naive predictor: 0.463\n",
        "      * Random Forest Classifier: 0.799"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiqYGzFUU_Ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "# create the dictionary of the parameters\n",
        "params_rfc = {'randomforestclassifier__n_estimators': n_estimators,\n",
        "              'randomforestclassifier__max_features': max_features,\n",
        "              'randomforestclassifier__max_depth': max_depth,\n",
        "              'randomforestclassifier__min_samples_split': min_samples_split,\n",
        "              'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
        "              'randomforestclassifier__bootstrap': bootstrap}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y5RSYT24Ne1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "3b52e72f-f417-45d3-87c7-b3693bbdac47"
      },
      "source": [
        "# build the pipeline\n",
        "rfc = RandomForestClassifier()\n",
        "pipe_rfc = make_pipeline(ct, rfc)\n",
        "rand_rfc = RandomizedSearchCV(pipe_rfc, params_rfc, n_iter = 6, cv = 5, verbose = 2, random_state = 1, n_jobs = 3)\n",
        "%time rand_rfc.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=3)]: Done  30 out of  30 | elapsed: 16.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.4 s, sys: 556 ms, total: 48.9 s\n",
            "Wall time: 17min 12s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('columntransformer',\n",
              "                                              ColumnTransformer(remainder='passthrough',\n",
              "                                                                transformers=[('onehotencoder',\n",
              "                                                                               OneHotEncoder(),\n",
              "                                                                               ['offer_id',\n",
              "                                                                                'gender',\n",
              "                                                                                'age_bin',\n",
              "                                                                                'income_bin',\n",
              "                                                                                'membership_since']),\n",
              "                                                                              ('standardscaler',\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               ['difficulty',\n",
              "                                                                                'duration',\n",
              "                                                                                'reward',\n",
              "                                                                                'total_amount'])])),\n",
              "                                             ('randomforestclassifier',\n",
              "                                              RandomFore...\n",
              "                                        'randomforestclassifier__max_depth': [10,\n",
              "                                                                              20,\n",
              "                                                                              30,\n",
              "                                                                              40,\n",
              "                                                                              50,\n",
              "                                                                              60,\n",
              "                                                                              70,\n",
              "                                                                              80,\n",
              "                                                                              90,\n",
              "                                                                              100,\n",
              "                                                                              110,\n",
              "                                                                              None],\n",
              "                                        'randomforestclassifier__max_features': ['auto',\n",
              "                                                                                 'sqrt'],\n",
              "                                        'randomforestclassifier__min_samples_leaf': [1,\n",
              "                                                                                     2,\n",
              "                                                                                     4],\n",
              "                                        'randomforestclassifier__min_samples_split': [2,\n",
              "                                                                                      5,\n",
              "                                                                                      10],\n",
              "                                        'randomforestclassifier__n_estimators': [200,\n",
              "                                                                                 400,\n",
              "                                                                                 600,\n",
              "                                                                                 800,\n",
              "                                                                                 1000,\n",
              "                                                                                 1200,\n",
              "                                                                                 1400,\n",
              "                                                                                 1600,\n",
              "                                                                                 1800,\n",
              "                                                                                 2000]},\n",
              "                   random_state=1, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yn4HbbG3jswi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a1778a71-fc8e-4e36-a819-46c257653d37"
      },
      "source": [
        "# print the results of the top estimators\n",
        "\n",
        "results = pd.DataFrame(rand_rfc.cv_results_)\n",
        "results.sort_values('rank_test_score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_randomforestclassifier__n_estimators</th>\n",
              "      <th>param_randomforestclassifier__min_samples_split</th>\n",
              "      <th>param_randomforestclassifier__min_samples_leaf</th>\n",
              "      <th>param_randomforestclassifier__max_features</th>\n",
              "      <th>param_randomforestclassifier__max_depth</th>\n",
              "      <th>param_randomforestclassifier__bootstrap</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.829873</td>\n",
              "      <td>2.238988</td>\n",
              "      <td>2.754379</td>\n",
              "      <td>0.146875</td>\n",
              "      <td>800</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>auto</td>\n",
              "      <td>40</td>\n",
              "      <td>False</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 800, ...</td>\n",
              "      <td>0.869925</td>\n",
              "      <td>0.869173</td>\n",
              "      <td>0.868045</td>\n",
              "      <td>0.871805</td>\n",
              "      <td>0.875846</td>\n",
              "      <td>0.870959</td>\n",
              "      <td>0.002733</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>94.893753</td>\n",
              "      <td>1.431579</td>\n",
              "      <td>3.953045</td>\n",
              "      <td>0.079983</td>\n",
              "      <td>1200</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>auto</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 1200,...</td>\n",
              "      <td>0.868233</td>\n",
              "      <td>0.869173</td>\n",
              "      <td>0.868515</td>\n",
              "      <td>0.871617</td>\n",
              "      <td>0.876598</td>\n",
              "      <td>0.870827</td>\n",
              "      <td>0.003122</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25.286658</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.861729</td>\n",
              "      <td>0.070979</td>\n",
              "      <td>200</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>auto</td>\n",
              "      <td>110</td>\n",
              "      <td>False</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 200, ...</td>\n",
              "      <td>0.869737</td>\n",
              "      <td>0.869079</td>\n",
              "      <td>0.867763</td>\n",
              "      <td>0.870019</td>\n",
              "      <td>0.876222</td>\n",
              "      <td>0.870564</td>\n",
              "      <td>0.002934</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>164.764823</td>\n",
              "      <td>2.612190</td>\n",
              "      <td>5.470978</td>\n",
              "      <td>0.154742</td>\n",
              "      <td>1200</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>auto</td>\n",
              "      <td>50</td>\n",
              "      <td>False</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 1200,...</td>\n",
              "      <td>0.871805</td>\n",
              "      <td>0.868797</td>\n",
              "      <td>0.864380</td>\n",
              "      <td>0.867293</td>\n",
              "      <td>0.872838</td>\n",
              "      <td>0.869023</td>\n",
              "      <td>0.003063</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>119.782003</td>\n",
              "      <td>4.206669</td>\n",
              "      <td>5.364707</td>\n",
              "      <td>0.196133</td>\n",
              "      <td>1200</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>auto</td>\n",
              "      <td>60</td>\n",
              "      <td>True</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 1200,...</td>\n",
              "      <td>0.867575</td>\n",
              "      <td>0.867669</td>\n",
              "      <td>0.865320</td>\n",
              "      <td>0.865977</td>\n",
              "      <td>0.869831</td>\n",
              "      <td>0.867274</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>58.904289</td>\n",
              "      <td>15.426622</td>\n",
              "      <td>2.043870</td>\n",
              "      <td>0.560503</td>\n",
              "      <td>1000</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>sqrt</td>\n",
              "      <td>10</td>\n",
              "      <td>True</td>\n",
              "      <td>{'randomforestclassifier__n_estimators': 1000,...</td>\n",
              "      <td>0.858177</td>\n",
              "      <td>0.863440</td>\n",
              "      <td>0.859868</td>\n",
              "      <td>0.865883</td>\n",
              "      <td>0.867857</td>\n",
              "      <td>0.863045</td>\n",
              "      <td>0.003610</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "3      91.829873      2.238988  ...        0.002733                1\n",
              "0      94.893753      1.431579  ...        0.003122                2\n",
              "1      25.286658      0.711111  ...        0.002934                3\n",
              "4     164.764823      2.612190  ...        0.003063                4\n",
              "2     119.782003      4.206669  ...        0.001567                5\n",
              "5      58.904289     15.426622  ...        0.003610                6\n",
              "\n",
              "[6 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z82DXWGzKi9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "92d31807-d3a4-491e-e6af-4e1378e5b636"
      },
      "source": [
        "# make the prediction from the test set with the best estimators\n",
        "\n",
        "y_pred_rfc = rand_rfc.predict(X_test)\n",
        "rfc_accuracy = accuracy_score(y_test, y_pred_rfc)\n",
        "rfc_f1 = f1_score(y_test, y_pred_rfc, average='binary')\n",
        "\n",
        "print('accuracy score of random forest classification: ', rfc_accuracy)\n",
        "print('F1 score of random forest classification: ', rfc_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score of random forest classification:  0.878355010901436\n",
            "F1 score of random forest classification:  0.8027791321306679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMMePYsse96I",
        "colab_type": "text"
      },
      "source": [
        "### **Construct XGBoost**\n",
        "* Perform randomized search of hyperparameter tuning\n",
        "* The results suggest that XGBoost could give the better accuracy f1-score than the naive predictor.\n",
        "    * Accuracy\n",
        "      * Naive predictor: 0.301\n",
        "      * XGBoost: 0.877\n",
        "    * F1-score\n",
        "      * Naive predictor: 0.463\n",
        "      * XGBoost: 0.797\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSNK0T_C8UO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of trees \n",
        "n_estimators = list(range(10, 1000, 100))\n",
        "\n",
        "# maximum number of levels in tree\n",
        "# control over-fitting as higher depth will allow model \n",
        "# to learn relations very specific to a particular sample\n",
        "max_depth = list(range(3, 13, 2)) \n",
        "\n",
        "# denotes the fraction of observations to be randomly samples for each tree.\n",
        "# lower values make the algorithm more conservative and \n",
        "# prevents overfitting but too small values might lead to under-fitting.\n",
        "subsamples = list(np.arange(0.5, 1, 0.1)) \n",
        "\n",
        "# decide learning rate and number of trees\n",
        "colsample_bytree = list(np.arange(0.5, 0.9, 0.1)) \n",
        "\n",
        "# defines the minimum sum of weights of all observations required in a child.\n",
        "# control over-fitting\n",
        "min_child_weight = [9, 12, 15]\n",
        "\n",
        "# define learning rate\n",
        "learning_rate = list(np.arange(0.1, 1, 0.1)) \n",
        "\n",
        "# specify the minimum loss reduction required to make a split.\n",
        "gamma = list(np.arange(0.1, 1, 0.1)) \n",
        "\n",
        "# create the dictionary of the parameters\n",
        "params_xgb = {'xgbclassifier__n_estimators': n_estimators,\n",
        "             'xgbclassifier__max_depth': max_depth,\n",
        "             'xgbclassifier__subsamples': subsamples,\n",
        "             'xgbclassifier__colsample_bytree': colsample_bytree,\n",
        "             'xgbclassifier__min_child_weight': min_child_weight,\n",
        "             'xgbclassifier__learning_rate': learning_rate,\n",
        "             'xgbclassifier__gamma': gamma}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT1r4PwRC8RD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab429c10-060b-418e-9fce-a6a63174165a"
      },
      "source": [
        "# create the pipeline\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "pipe_xgb = make_pipeline(ct, xgb)\n",
        "rand_xgb = RandomizedSearchCV(pipe_xgb, params_xgb, n_iter = 6, cv = 5, verbose = 2 , random_state=42)# Fit the random search model\n",
        "%time rand_xgb.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7, total=  15.0s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7, total=  14.9s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7, total=  14.9s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7, total=  14.9s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=110, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=9, xgbclassifier__learning_rate=0.1, xgbclassifier__gamma=0.1, xgbclassifier__colsample_bytree=0.7, total=  14.8s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7, total=  42.7s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7, total=  42.6s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7, total=  42.5s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7, total=  43.4s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.4, xgbclassifier__colsample_bytree=0.7, total=  43.0s\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7, total= 1.4min\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7, total= 1.4min\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7, total= 1.4min\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7, total= 1.4min\n",
            "[CV] xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7 \n",
            "[CV]  xgbclassifier__subsamples=0.7, xgbclassifier__n_estimators=610, xgbclassifier__min_child_weight=12, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.5, xgbclassifier__gamma=0.2, xgbclassifier__colsample_bytree=0.7, total= 1.4min\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6, total=  44.9s\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6, total=  47.2s\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6, total=  44.6s\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6, total=  46.7s\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=810, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=5, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.7000000000000001, xgbclassifier__colsample_bytree=0.6, total=  46.7s\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6, total= 1.1min\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6, total= 1.1min\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6, total= 1.1min\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6, total= 1.1min\n",
            "[CV] xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.8999999999999999, xgbclassifier__n_estimators=510, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=11, xgbclassifier__learning_rate=0.7000000000000001, xgbclassifier__gamma=0.9, xgbclassifier__colsample_bytree=0.6, total= 1.0min\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6, total=  11.7s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6, total=  12.0s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6, total=  12.1s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6, total=  11.9s\n",
            "[CV] xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6 \n",
            "[CV]  xgbclassifier__subsamples=0.7999999999999999, xgbclassifier__n_estimators=310, xgbclassifier__min_child_weight=9, xgbclassifier__max_depth=3, xgbclassifier__learning_rate=0.4, xgbclassifier__gamma=0.8, xgbclassifier__colsample_bytree=0.6, total=  12.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 21.9min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 22min 44s, sys: 1.12 s, total: 22min 45s\n",
            "Wall time: 22min 46s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5,\n",
              "                   estimator=Pipeline(steps=[('columntransformer',\n",
              "                                              ColumnTransformer(remainder='passthrough',\n",
              "                                                                transformers=[('onehotencoder',\n",
              "                                                                               OneHotEncoder(),\n",
              "                                                                               ['offer_id',\n",
              "                                                                                'gender',\n",
              "                                                                                'age_bin',\n",
              "                                                                                'income_bin',\n",
              "                                                                                'membership_since']),\n",
              "                                                                              ('standardscaler',\n",
              "                                                                               StandardScaler(),\n",
              "                                                                               ['difficulty',\n",
              "                                                                                'duration',\n",
              "                                                                                'reward',\n",
              "                                                                                'total_amount'])])),\n",
              "                                             ('xgbclassifier',\n",
              "                                              XGBClassifier())]),...\n",
              "                                        'xgbclassifier__learning_rate': [0.1,\n",
              "                                                                         0.2,\n",
              "                                                                         0.30000000000000004,\n",
              "                                                                         0.4,\n",
              "                                                                         0.5,\n",
              "                                                                         0.6,\n",
              "                                                                         0.7000000000000001,\n",
              "                                                                         0.8,\n",
              "                                                                         0.9],\n",
              "                                        'xgbclassifier__max_depth': [3, 5, 7, 9,\n",
              "                                                                     11],\n",
              "                                        'xgbclassifier__min_child_weight': [9,\n",
              "                                                                            12,\n",
              "                                                                            15],\n",
              "                                        'xgbclassifier__n_estimators': [10, 110,\n",
              "                                                                        210,\n",
              "                                                                        310,\n",
              "                                                                        410,\n",
              "                                                                        510,\n",
              "                                                                        610,\n",
              "                                                                        710,\n",
              "                                                                        810,\n",
              "                                                                        910],\n",
              "                                        'xgbclassifier__subsamples': [0.5, 0.6,\n",
              "                                                                      0.7,\n",
              "                                                                      0.7999999999999999,\n",
              "                                                                      0.8999999999999999]},\n",
              "                   random_state=42, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XrtDj_VQVTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a57433f3-fd63-424b-9d94-c413527a2591"
      },
      "source": [
        "# print the results of the top estimators\n",
        "results = pd.DataFrame(rand_xgb.cv_results_)\n",
        "results.sort_values('rank_test_score')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_xgbclassifier__subsamples</th>\n",
              "      <th>param_xgbclassifier__n_estimators</th>\n",
              "      <th>param_xgbclassifier__min_child_weight</th>\n",
              "      <th>param_xgbclassifier__max_depth</th>\n",
              "      <th>param_xgbclassifier__learning_rate</th>\n",
              "      <th>param_xgbclassifier__gamma</th>\n",
              "      <th>param_xgbclassifier__colsample_bytree</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42.533662</td>\n",
              "      <td>0.302615</td>\n",
              "      <td>0.303841</td>\n",
              "      <td>0.003287</td>\n",
              "      <td>0.7</td>\n",
              "      <td>310</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.7, 'xgbclassif...</td>\n",
              "      <td>0.872838</td>\n",
              "      <td>0.873120</td>\n",
              "      <td>0.874060</td>\n",
              "      <td>0.880263</td>\n",
              "      <td>0.876598</td>\n",
              "      <td>0.875376</td>\n",
              "      <td>0.002780</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>83.183457</td>\n",
              "      <td>1.568517</td>\n",
              "      <td>0.641075</td>\n",
              "      <td>0.016044</td>\n",
              "      <td>0.7</td>\n",
              "      <td>610</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.7, 'xgbclassif...</td>\n",
              "      <td>0.873308</td>\n",
              "      <td>0.872744</td>\n",
              "      <td>0.874718</td>\n",
              "      <td>0.877914</td>\n",
              "      <td>0.875940</td>\n",
              "      <td>0.874925</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>62.689007</td>\n",
              "      <td>0.670043</td>\n",
              "      <td>0.313672</td>\n",
              "      <td>0.022257</td>\n",
              "      <td>0.9</td>\n",
              "      <td>510</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.89999999999999...</td>\n",
              "      <td>0.875094</td>\n",
              "      <td>0.869925</td>\n",
              "      <td>0.873590</td>\n",
              "      <td>0.875376</td>\n",
              "      <td>0.875282</td>\n",
              "      <td>0.873853</td>\n",
              "      <td>0.002069</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.783141</td>\n",
              "      <td>0.046057</td>\n",
              "      <td>0.100253</td>\n",
              "      <td>0.001873</td>\n",
              "      <td>0.8</td>\n",
              "      <td>110</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.79999999999999...</td>\n",
              "      <td>0.866729</td>\n",
              "      <td>0.869737</td>\n",
              "      <td>0.870019</td>\n",
              "      <td>0.875188</td>\n",
              "      <td>0.874718</td>\n",
              "      <td>0.871278</td>\n",
              "      <td>0.003218</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>45.781650</td>\n",
              "      <td>1.081995</td>\n",
              "      <td>0.227875</td>\n",
              "      <td>0.005409</td>\n",
              "      <td>0.9</td>\n",
              "      <td>810</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.89999999999999...</td>\n",
              "      <td>0.868233</td>\n",
              "      <td>0.866917</td>\n",
              "      <td>0.871147</td>\n",
              "      <td>0.873214</td>\n",
              "      <td>0.872556</td>\n",
              "      <td>0.870414</td>\n",
              "      <td>0.002448</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11.867162</td>\n",
              "      <td>0.138164</td>\n",
              "      <td>0.090058</td>\n",
              "      <td>0.003809</td>\n",
              "      <td>0.8</td>\n",
              "      <td>310</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'xgbclassifier__subsamples': 0.79999999999999...</td>\n",
              "      <td>0.863816</td>\n",
              "      <td>0.868703</td>\n",
              "      <td>0.867669</td>\n",
              "      <td>0.869455</td>\n",
              "      <td>0.872274</td>\n",
              "      <td>0.868383</td>\n",
              "      <td>0.002748</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "1      42.533662      0.302615  ...        0.002780                1\n",
              "2      83.183457      1.568517  ...        0.001864                2\n",
              "4      62.689007      0.670043  ...        0.002069                3\n",
              "0      14.783141      0.046057  ...        0.003218                4\n",
              "3      45.781650      1.081995  ...        0.002448                5\n",
              "5      11.867162      0.138164  ...        0.002748                6\n",
              "\n",
              "[6 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yy_9keuvQVNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "91fc0919-a5b7-4d19-99ac-dff4bafc1144"
      },
      "source": [
        "# make the prediction from the test set with the best estimators\n",
        "\n",
        "y_pred_xgb = rand_xgb.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
        "xgb_f1 = f1_score(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "print('accuracy score of xgboost: ', xgb_accuracy)\n",
        "print('F1 score of xgboost: ', xgb_f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score of xgboost:  0.8771520938275318\n",
            "F1 score of xgboost:  0.7971698113207547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2cfDFO6fv0v",
        "colab_type": "text"
      },
      "source": [
        "### **Tune the best model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYV1lj2cxTpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "ab53ccb3-3978-464b-be6e-9172d9aa75ce"
      },
      "source": [
        "score_metrics = {'model': ['naive predictor', 'logistic regression', ' random forest classifier', 'xgboost'],\n",
        "                 'accuracy': [naive_pred_accuracy, lr_accuracy, rfc_accuracy, xgb_accuracy],\n",
        "                 'F1 score': [naive_pred_f1, lr_f1, rfc_f1, xgb_f1]}\n",
        "\n",
        "score_metrics_df = pd.DataFrame(score_metrics, columns= ['model', 'accuracy', 'F1 score'])\n",
        "score_metrics_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>naive predictor</td>\n",
              "      <td>0.301222</td>\n",
              "      <td>0.462983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>logistic regression</td>\n",
              "      <td>0.791519</td>\n",
              "      <td>0.572793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>random forest classifier</td>\n",
              "      <td>0.878355</td>\n",
              "      <td>0.802779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>0.877152</td>\n",
              "      <td>0.797170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       model  accuracy  F1 score\n",
              "0            naive predictor  0.301222  0.462983\n",
              "1        logistic regression  0.791519  0.572793\n",
              "2   random forest classifier  0.878355  0.802779\n",
              "3                    xgboost  0.877152  0.797170"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPxKn_DrXgf-",
        "colab_type": "text"
      },
      "source": [
        "The best model is the random forest classifier. Let's print out the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhtbjnJwXm05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "86d1cce4-2e21-4baa-ab17-af3e2092a03b"
      },
      "source": [
        "print('confusion matrix of random forest classifier:\\n', confusion_matrix(y_test, y_pred_rfc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "confusion matrix of random forest classifier:\n",
            " [[8390  944]\n",
            " [ 674 3293]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaxnFoRnWU1a",
        "colab_type": "text"
      },
      "source": [
        "### **Conclusion**\n",
        "\n",
        "It is not an easy task to create a decent modeling on marketing campaign due to many factors such as unpredicable human behaviours and economic cycles etc. \n",
        "\n",
        "In this project, I tried to accomplish a more convining model by combining the  business heuristics knowledge and the machine learning approach. Hope that would give some insights on the future marketing campaign.\n",
        "\n",
        "Notes of this project:\n",
        "\n",
        "* I removed several samlpe with age 118 because these samples are also lack of many features. I strongly believe the samples of age 118 are Nan. It is a good learning process to the business world.\n",
        "\n",
        "*   Female customers have higher density in higher income spectum (75k up)   while male custoers have higher density in lower income spectum (75k below).\n",
        "\n",
        "\n",
        "Finally, I am impressed that the random forest classifer explain the dataset with 88% accuracy and 80% F1 score.\n",
        "\n"
      ]
    }
  ]
}